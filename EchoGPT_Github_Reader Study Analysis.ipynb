{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24078a25-6e53-40ca-9a87-d97279b3b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae419d51-2f52-42bd-b3b2-839d9aa9b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"file_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0fcb78-8ec0-41b8-b940-8f053bad6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list of categories (e.g., Completeness, Conciseness, Correctness, Clinical Utility)\n",
    "categories = ['Completeness', 'Conciseness', 'Correctness', 'Clinical Utility']\n",
    "\n",
    "# Create a new DataFrame for the stacked values\n",
    "stacked_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through categories and stack the values into individual cells\n",
    "for category in categories:\n",
    "    category_columns = [col for col in df.columns if col.startswith(category)]\n",
    "    stacked_df[category] = df[category_columns].values.ravel()\n",
    "    \n",
    "for i in range(0,len(stacked_df)):\n",
    "    stacked_df.loc[i,\"Reader\"]=df[\"Name\"][i // 30]\n",
    "\n",
    "print(stacked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4deadb-90be-4b14-81ef-9436ef150911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding dictionary (5-class)\n",
    "encoding_dict = {\n",
    "    \"Summary A\": -10,\n",
    "    \"Summary A slightly\": -5,\n",
    "    \"Neutral\": 0,\n",
    "    \"Summary B slightly\": 5,\n",
    "    \"Summary B\": 10\n",
    "}\n",
    "\n",
    "# Map the encoding to the stacked DataFrame\n",
    "stacked_df_encoded = stacked_df.applymap(lambda x: encoding_dict.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a8b9fd-e6f0-4558-a4b1-5cbd561aafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Pearson correlation matrix\n",
    "correlation_matrix = stacked_df_encoded.corr()\n",
    "\n",
    "# Create a mask to show only the lower triangle of the correlation matrix\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Create a heatmap to visualize the lower triangle of the correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, mask=mask)\n",
    "plt.title('Pearson Correlation Heatmap (Lower Triangle)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a937169-7211-49bf-8842-7ecc1d7b10dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already created the stacked_df_encoded DataFrame\n",
    "\n",
    "# Calculate the mean and std for each category\n",
    "mean_values = stacked_df_encoded.mean()\n",
    "std_values = stacked_df_encoded.std()\n",
    "\n",
    "# Create a horizontal bar plot for the mean values\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=mean_values.values, y=mean_values.index, orient='horizontal')\n",
    "plt.title('Mean Values for Categories')\n",
    "\n",
    "# Set the x-axis limits\n",
    "plt.xlim(-10, 10)\n",
    "\n",
    "# Custom tick locations and labels\n",
    "custom_labels = {\"Echo Expert significantly\": -10, \"Echo Expert slightly\": -5, \"Neutral\": 0, \"EchoGPT slightly\": 5, \"EchoGPT significantly\": 10}\n",
    "tick_locations = list(custom_labels.values())\n",
    "tick_labels = [f\"{value}\\n{label}\" for label, value in custom_labels.items()]  # Use \\n for line break\n",
    "\n",
    "# Set the x-axis ticks and labels\n",
    "plt.xticks(tick_locations, tick_labels)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fe58f2-7003-4394-9b82-d018c566a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the DataFrame 'stacked_df_encoded' is available with the relevant data\n",
    "# For demonstration, I will create a sample DataFrame\n",
    "# Replace this with your actual DataFrame\n",
    "\n",
    "# Calculate the mean and std for each category\n",
    "mean_values = stacked_df_encoded.mean()\n",
    "std_values = stacked_df_encoded.std()\n",
    "\n",
    "# Create a horizontal bar plot for the mean values\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=mean_values.values, y=mean_values.index, orient='horizontal')\n",
    "plt.title('Mean Values for Categories')\n",
    "\n",
    "# Set the x-axis limits\n",
    "plt.xlim(-10, 10)\n",
    "\n",
    "# Custom tick locations and labels\n",
    "custom_labels = {\n",
    "    \"Echo Expert significantly\": -10, \n",
    "    \"Echo Expert slightly\": -5, \n",
    "    \"Neutral\": 0, \n",
    "    \"EchoGPT slightly\": 5, \n",
    "    \"EchoGPT significantly\": 10\n",
    "}\n",
    "tick_locations = list(custom_labels.values())\n",
    "tick_labels = [f\"{value}\\n{label}\" for label, value in custom_labels.items()]  # Use \\n for line break\n",
    "\n",
    "# Set the x-axis ticks and labels with bold font\n",
    "plt.xticks(tick_locations, tick_labels, fontweight='bold')\n",
    "\n",
    "# Set the y-axis labels with bold font\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontweight('bold')\n",
    "\n",
    "# Add text for mean ± std on the right of each bar\n",
    "for i, (mean, std) in enumerate(zip(mean_values, std_values)):\n",
    "    ax.text(mean + 0.3, i, f'{mean:.2f} ± {std:.2f}', color='black', va='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a1645-2d14-4c30-b774-b12bb9865a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "categories = ['Completeness', 'Conciseness', 'Correctness', 'Clinical Utility']\n",
    "\n",
    "# Perform the one-sample Wilcoxon signed-rank test\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "for category in categories:\n",
    "    # Get the ratings for the current category\n",
    "    category_ratings = stacked_df_encoded[category]\n",
    "    \n",
    "    # Perform the one-sample Wilcoxon signed-rank test\n",
    "    statistic, p_value = wilcoxon(category_ratings, zero_method='pratt')\n",
    "    \n",
    "    # Print results for the current category\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"Test Statistic: {statistic}\")\n",
    "    print(f\"P-Value: {p_value}\")\n",
    "    \n",
    "    # Determine if there is a significant difference\n",
    "    if p_value < alpha:\n",
    "        print(\"Conclusion: The preferences significantly deviate from a hypothetical median of 0.\")\n",
    "    else:\n",
    "        print(\"Conclusion: There is no significant deviation from a hypothetical median of 0 in preferences.\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f44b1-103d-4c65-9a23-89ba8276f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare case raw scores to expert rates\n",
    "import pandas as pd\n",
    "score=pd.read_excel(\"file_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03828aa8-e464-435e-a4fb-7f0619f80b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create average df\n",
    "# Encoding dictionary\n",
    "encoding_dict = {\n",
    "    \"Summary A\": -10,\n",
    "    \"Summary A slightly\": -5,\n",
    "    \"Neutral\": 0,\n",
    "    \"Summary B slightly\": 5,\n",
    "    \"Summary B\": 10\n",
    "}\n",
    "\n",
    "# Map the encoding to the stacked DataFrame\n",
    "df_encoded = df.applymap(lambda x: encoding_dict.get(x, x))\n",
    "\n",
    "# List of categories to consider\n",
    "categories = ['Completeness', 'Conciseness', 'Correctness', 'Clinical Utility']\n",
    "\n",
    "# Select columns containing category names\n",
    "selected_columns = [col for col in df_encoded.columns if any(category in col for category in categories)]\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "selected_df = df_encoded[selected_columns]\n",
    "\n",
    "mean_df=pd.DataFrame(selected_df.mean()).T\n",
    "\n",
    "# Display the selected DataFrame\n",
    "print(mean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5f332-239a-4d68-99c9-562d76ff4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categories to consider\n",
    "categories = ['Completeness', 'Conciseness', 'Correctness', 'Clinical Utility']\n",
    "\n",
    "# Create a new DataFrame to store the stacked values\n",
    "stacked_mean_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through categories and stack the values\n",
    "for category in categories:\n",
    "    category_columns = [col for col in mean_df.columns if col.startswith(category)]\n",
    "    stacked_mean_df[category] = mean_df[category_columns].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4744c8-c241-499c-8ee1-e97b7e467cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Assuming df1 contains columns [BLEU Score, METEOR Score, ROUGE-L Score, BERT Score, F1RadGraph Score]\n",
    "# and df2 contains columns [Completeness, Conciseness, Correctness, Clinical Utility]\n",
    "df1=score\n",
    "df2=stacked_mean_df\n",
    "\n",
    "# Select the columns from the DataFrames\n",
    "columns_df1 = [\"BLEU Score\", \"METEOR Score\", \"ROUGE-L Score\", \"BERT Score\", \"F1RadGraph Score\"]\n",
    "columns_df2 = [\"Completeness\", \"Conciseness\", \"Correctness\", \"Clinical Utility\"]\n",
    "\n",
    "# Create an empty correlation matrix\n",
    "correlation_matrix = pd.DataFrame(columns=columns_df1, index=columns_df2)\n",
    "\n",
    "# Calculate Pearson correlation for each pair of columns\n",
    "for col1 in columns_df1:\n",
    "    for col2 in columns_df2:\n",
    "        correlation, _ = pearsonr(df1[col1], df2[col2])\n",
    "        correlation_matrix.at[col2, col1] = correlation\n",
    "\n",
    "# Create a heatmap to visualize the correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix.astype(float), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "\n",
    "# Set plot title\n",
    "plt.title(\"Pearson Correlation Heatmap\")\n",
    "plt.ylabel(\"4C Qualitative Metrics\")\n",
    "plt.xlabel(\"Automatic Metrics\")\n",
    "\n",
    "# Show the heatmap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db16e331-dc3b-4f98-bbcf-ffa1653805f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Kappa (5-class)\n",
    "import pandas as pd\n",
    "import krippendorff\n",
    "\n",
    "# Assuming you have a DataFrame 'stacked_df_encoded' with columns ['Completeness', 'Conciseness', 'Correctness', 'Clinical Utility', 'Reader']\n",
    "\n",
    "# Create a list of interested parameters\n",
    "parameters = ['Completeness', 'Conciseness', 'Correctness', 'Clinical Utility']\n",
    "readers= stacked_df_encoded[\"Reader\"].unique()\n",
    "\n",
    "# Create an empty list to store the kappa values for each parameter\n",
    "kappa_values = []\n",
    "\n",
    "# Iterate through each parameter and calculate Fleiss' Kappa\n",
    "for parameter in parameters:\n",
    "    # Group the DataFrame by the parameter and calculate the mode for each group\n",
    "    #parameter_groups = stacked_df_encoded.groupby(parameter)['Reader'].apply(lambda x: x.mode().iloc[0]).reset_index()\n",
    "    \n",
    "    # Convert the mode values to a list of lists for each item\n",
    "    ratings = [stacked_df_encoded[stacked_df_encoded[\"Reader\"]==readers[0]][parameter],\n",
    "               stacked_df_encoded[stacked_df_encoded[\"Reader\"]==readers[1]][parameter],\n",
    "               stacked_df_encoded[stacked_df_encoded[\"Reader\"]==readers[2]][parameter],\n",
    "               stacked_df_encoded[stacked_df_encoded[\"Reader\"]==readers[3]][parameter]]\n",
    "    \n",
    "    # Calculate Fleiss' Kappa for the parameter\n",
    "    kappa = krippendorff.alpha(reliability_data=ratings)\n",
    "    \n",
    "    # Append the kappa value to the list\n",
    "    kappa_values.append((parameter, kappa))\n",
    "\n",
    "# Print the kappa values for each parameter\n",
    "for parameter, kappa in kappa_values:\n",
    "    print(f\"Fleiss' Kappa for {parameter}: {kappa:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

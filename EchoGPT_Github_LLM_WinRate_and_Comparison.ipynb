{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##LLM Win Rate"
      ],
      "metadata": {
        "id": "TTsioRpzMwJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "blvD6syuVvpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the raw scores of each model\n",
        "LLAMA2_FT=pd.read_excel(\"/content/raw_scores-AZval-LlamaFT-1-25-24.xlsx\")\n",
        "LLAMA2_ZS=pd.read_excel(\"/content/raw_scores-ZS-Llama-AZval-1-25-24.xlsx\")\n",
        "MedAlp_ZS=pd.read_excel(\"/content/MedAlp-ZS-AZval-1-25-24.xlsx\")\n",
        "Zephyr_FT=pd.read_excel(\"/content/raw_scores-AZval-ZeFT-1-25-24.xlsx\")\n",
        "Zephyr_ZS=pd.read_excel(\"/content/ZeZS-raw_scores-AZval-1-25-24.xlsx\")\n",
        "T5_ZS=pd.read_excel(\"/content/raw_scores-ZS-T5-AZval-1-25-24.xlsx\")"
      ],
      "metadata": {
        "id": "q3dnsyMpVygQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have loaded the Excel file into the respective DataFrames, here's the code for one of the DataFrames:\n",
        "# Fill NaN with 0 *Some metrics return NaN if failed.\n",
        "Zephyr_FT.fillna(0, inplace=True)\n",
        "\n",
        "# Rename the 'F1RadGraph Score' column to 'RadGraph F1'\n",
        "Zephyr_FT.rename(columns={'F1RadGraph Score': 'RadGraph F1'}, inplace=True)\n",
        "\n",
        "# Repeat the above two steps for the other DataFrames as needed\n",
        "MedAlp_ZS.fillna(0, inplace=True)\n",
        "MedAlp_ZS.rename(columns={'F1RadGraph Score': 'RadGraph F1'}, inplace=True)\n",
        "\n",
        "LLAMA2_FT.fillna(0, inplace=True)\n",
        "LLAMA2_FT.rename(columns={'F1RadGraph Score': 'RadGraph F1'}, inplace=True)\n",
        "\n",
        "LLAMA2_ZS.fillna(0, inplace=True)\n",
        "LLAMA2_ZS.rename(columns={'F1RadGraph Score': 'RadGraph F1'}, inplace=True)\n",
        "\n",
        "Zephyr_ZS.fillna(0, inplace=True)\n",
        "Zephyr_ZS.rename(columns={'F1RadGraph Score': 'RadGraph F1'}, inplace=True)\n",
        "\n",
        "T5_ZS.fillna(0, inplace=True)\n",
        "T5_ZS.rename(columns={'F1RadGraph Score': 'RadGraph F1'}, inplace=True)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(Zephyr_FT)\n"
      ],
      "metadata": {
        "id": "ccNYzT8TWIsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct data matrix\n",
        "# Extract the \"BLEU Score\" column from each DataFrame and add a \"Model\" column\n",
        "LLAMA2_FT['Model'] = 'Llama2_FT'\n",
        "LLAMA2_ZS['Model'] = 'Llama2_ZS'\n",
        "MedAlp_ZS['Model'] = 'MedAlp_ZS'\n",
        "Zephyr_FT['Model'] = 'Zephyr_FT'\n",
        "Zephyr_ZS['Model'] = 'Zephyr_ZS'\n",
        "T5_ZS['Model'] = 'T5_ZS'\n",
        "\n",
        "# Metric to use\n",
        "Score = \"RadGraph F1\"\n",
        "\n",
        "# Stack the DataFrames vertically\n",
        "stacked_df = pd.concat([LLAMA2_FT[[Score, 'Model']], LLAMA2_ZS[[Score, 'Model']], MedAlp_ZS[[Score, 'Model']], Zephyr_FT[[Score, 'Model']], Zephyr_ZS[[Score, 'Model']], T5_ZS[[Score, 'Model']]])\n",
        "\n",
        "# Reset the index of the stacked DataFrame\n",
        "stacked_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "print(stacked_df)\n"
      ],
      "metadata": {
        "id": "UF4mt03wMvQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulated data with variations\n",
        "\n",
        "# Define the metric you want to compare (e.g., 'BLEU Score', 'METEOR Score', etc.)\n",
        "selected_metric = Score\n",
        "\n",
        "# Create a DataFrame from the data\n",
        "df = stacked_df\n",
        "\n",
        "# Calculate the win rate percentiles for each model pair based on the selected metric\n",
        "combinations = []\n",
        "for model1 in df['Model'].unique():\n",
        "    for model2 in df['Model'].unique():\n",
        "        if model1 != model2:\n",
        "            metric1 = df[df['Model'] == model1][selected_metric].values\n",
        "            metric2 = df[df['Model'] == model2][selected_metric].values\n",
        "            metric_win = (metric1 > metric2).mean() * 100  # Calculate the win rate as a percentile\n",
        "            combinations.append([model1, model2, metric_win])\n",
        "\n",
        "combinations_df = pd.DataFrame(combinations, columns=['Model1', 'Model2', f'{selected_metric} Win Rate'])\n",
        "\n",
        "# Create a pivot table to prepare the data for visualization\n",
        "pivot_table = combinations_df.pivot('Model1', 'Model2', f'{selected_metric} Win Rate')\n",
        "\n",
        "# Create a mask to show only the lower corner of the heatmap\n",
        "#mask = np.triu(np.ones_like(pivot_table, dtype=bool))\n",
        "mask = np.tril(np.ones_like(pivot_table, dtype=bool))\n",
        "\n",
        "# Create a color map for the color bar\n",
        "cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
        "\n",
        "# Create a heatmap to visualize win rate comparisons for the selected metric (lower corner only)\n",
        "plt.figure(figsize=(8, 6))\n",
        "ax = sns.heatmap(pivot_table, annot=True, fmt='.1f', cmap=cmap, cbar=True, mask=mask)\n",
        "\n",
        "ax.annotate(\"Box Font Size\", xy=(-0.5, -0.5), fontsize=25)\n",
        "\n",
        "# Change x and y-axis labels\n",
        "ax.set_title(f'{selected_metric} Win Rate Comparisons')\n",
        "ax.set_xlabel('...against this model', fontweight='bold')\n",
        "ax.set_ylabel('Win rate of this model...',  fontweight='bold')\n",
        "\n",
        "# Tilt the y-axis labels\n",
        "plt.yticks(rotation=45)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Qs2VxQoaUhxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statistical Comparison of Selected Model Pairs"
      ],
      "metadata": {
        "id": "I5p6f2LbSjnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import shapiro, ttest_rel, wilcoxon\n",
        "\n",
        "# Load the first Excel spreadsheet into a DataFrame\n",
        "file1 = \"file_path1\"  # Replace with the actual file path\n",
        "df1 = pd.read_excel(file1)\n",
        "\n",
        "# Load the second Excel spreadsheet into another DataFrame\n",
        "file2 = \"file_path2\"  # Replace with the actual file path\n",
        "df2 = pd.read_excel(file2)\n",
        "\n",
        "# List of parameters you want to test\n",
        "parameters = ['BLEU Score', 'METEOR Score', 'ROUGE-L Score', 'BERT Score', 'RadGraph F1']\n",
        "\n",
        "# Initialize a list to store test results\n",
        "test_results = []\n",
        "\n",
        "# Loop through each parameter\n",
        "for param in parameters:\n",
        "    # Extract data for the current parameter from both DataFrames\n",
        "    data1 = df1[param]\n",
        "    data2 = df2[param]\n",
        "\n",
        "    # Perform a normality test (Shapiro-Wilk) for each dataset\n",
        "    _, p_value1 = shapiro(data1)\n",
        "    _, p_value2 = shapiro(data2)\n",
        "\n",
        "    # Perform a paired t-test for normally distributed data\n",
        "    if p_value1 > 0.05 and p_value2 > 0.05:\n",
        "        _, p_value = ttest_rel(data1, data2)\n",
        "    else:\n",
        "        # Perform a Wilcoxon signed-rank test for non-normally distributed data\n",
        "        _, p_value = wilcoxon(data1, data2, alternative='two-sided')\n",
        "\n",
        "    test_results.append((param, p_value))\n",
        "\n",
        "# Print the test results\n",
        "for param, p_value in test_results:\n",
        "    print(f\"Parameter: {param}\")\n",
        "    print(f\"p-value: {p_value:.4f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "SfZYnxkiSptt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}